import streamlit as st
from dotenv import load_dotenv
import base64
load_dotenv()
import asyncio
import os
from datetime import datetime
from agents import InputGuardrail, GuardrailFunctionOutput, Agent, Runner, OpenAIChatCompletionsModel, function_tool, set_tracing_disabled
from agents.exceptions import InputGuardrailTripwireTriggered
from openai import AsyncAzureOpenAI
import requests
from pydantic import BaseModel
from typing import Literal

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Chatbot √Ålvaro - OpenAI Agents",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'mailto:alvaroglezb@gmail.com'
    }
)

# CSS personalizado para mejorar el dise√±o
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
    }
    
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid;
    }
    
    .user-message {
    background-color: #D44E4E;   /* gris azulado muy claro */
    border-left-color: #F5F5F5; /* azul gris√°ceo */
    }

    .assistant-message {
    background-color: #4E81D4;   /* gris lila claro */
    border-left-color: #F5F5F5;  /* p√∫rpura apagado */
    }
    
    .error-message {
        background-color: #ffebee;
        border-left-color: #f44336;
    }
    
    .warning-message {
        background-color: #fff3e0;
        border-left-color: #ff9800;
    }
    
    .success-message {
        background-color: #e8f5e8;
        border-left-color: #4caf50;
    }
    
    .metrics-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

## --- CONFIGURACI√ìN INICIAL ---##
# Context sobre √Ålvaro
CONTEXT = """
# Perfil Personal - √Ålvaro Gonz√°lez Bielza

## üìã Informaci√≥n B√°sica
| Campo | Informaci√≥n |
|-------|-------------|
| **Nombre** | √Ålvaro |
| **Primer Apellido** | Gonz√°lez |
| **Segundo Apellido** | Bielza |
| **Nombre Completo** | √Ålvaro Gonz√°lez Bielza |

## üìè Caracter√≠sticas F√≠sicas
- **Altura**: 1,75 cm
- **Peso**: 70 Kg

## üé® Preferencias
- **Color Favorito**: Azul
Aqu√≠ tienes el contenido del CV convertido a formato Markdown:

---

# √Ålvaro Gonz√°lez Bielza

**Ingeniero Industrial**
üìû 651191316 | üìß [alvaroglezb@gmail.com](mailto:alvaroglezb@gmail.com)
üîó [LinkedIn](https://www.linkedin.com/in/alvarogonzalezbielza)

---

## Perfil

Consultor tecnol√≥gico con s√≥lida experiencia en automatizaci√≥n inteligente e inteligencia artificial generativa. Especializado en todo el ciclo de vida de un proyecto de automatizaci√≥n con herramientas como UiPath y Azure. Experiencia en gesti√≥n de equipos multidisciplinarios e implementaci√≥n de m√∫ltiples soluciones en entornos productivos en cliente final.

---

## Experiencia

### CONSULTOR SENIOR DTO. DIGITAL ENGINEERING | EY (Ernst & Young)

**Diciembre de 2021 ‚Äì Presente**

**Proyecto destacado:** Automatizaci√≥n Inteligente en la Agencia Digital de Andaluc√≠a

* **Rol:** Responsable de negocio (habiendo pasado por desarrollador y consultor). Equipo formado por 40 personas, responsable de 16 consultores y desarrolladores.
* **Cliente:** Agencia Digital de Andaluc√≠a
* **Periodo:** 2021 ‚Äì presente
* **Logros clave:**

  * Ahorro generado > 40M ‚Ç¨
  * Automatizaci√≥n de > 100 procesos
  * Procesamiento de > 3M de documentos
  * Iniciativa UAI DOC: Tratamiento documental con IA (Premio Socinfo)
  * Impacto eficiencia: > 2,4 M expedientes procesados
  * Desarrollo de componentes reutilizables entre consejer√≠as para facilitar escalabilidad
* **Retos:**

  * Alto volumen de procesos en planificaci√≥n
  * Inclusi√≥n de cuadros de mando con Kibana
  * Cliente presente en m√∫ltiples consejer√≠as
  * Puesta en producci√≥n de soluci√≥n con IA generativa
  * Balancear la carga del equipo seg√∫n desarrollos en curso

---

## Educaci√≥n

* **M√°ster Habilitante en Ingenier√≠a Industrial**
  *2020 ‚Äì 2022 | Universidad Polit√©cnica de Madrid*

* **Grado en Ingenier√≠a en Organizaci√≥n Industrial**
  *2015 ‚Äì 2019 | Universidad de Sevilla*

---

## Certificaciones y Cursos Adicionales

* **Microsoft AI-102 AI Engineer Associate**
  ID: B37808685713A12D

* **Founderz Master Online IA e Innovaci√≥n**
  ID: e85010b5-a094-40d0-9a92-1e391635c242

* **Formador en curso de RPA para la Junta de Extremadura (150h)**

* **IBM Watsonx Orchestrate Sales Foundation**

* **McKinsey Forward Program**

* **EY Artificial Intelligence ‚Äì AI Engineering**

* **UiPath RPA Developer Foundation**

* **Professional Scrum Master** *(en preparaci√≥n)*

---

## Aptitudes y Habilidades

### Hard Skills

* **Azure AI Services (Avanzado):**
  Document Intelligence, AI Search, Azure OpenAI, Key Vault, Azure Storage, Azure Functions
* **UiPath (Avanzado):**
  ReFramework, Orchestrator
* **Python (Intermedio):**
  Funciones Azure, informes con APIs y Pandas
* **SQL (Avanzado):**
  Queries para integraci√≥n con RPA y Azure, esquemas E/R (3FN)
* **Consumo de APIs (Avanzado)**
* **Power Platform (B√°sico)**
* **Kibana (B√°sico)**
* **Documentaci√≥n de ciclo de vida de proyectos:**
  PDD, SDD, UAT, PRN
* **Azure DevOps (Avanzado):**
  Gesti√≥n de proyectos, consumo por APIs, informes

### Soft Skills

* **Ingl√©s (Avanzado)**
* Comunicaci√≥n efectiva con cliente, comprensi√≥n de necesidades
* Reporting semanal de KPIs y estado de proyecto
* Capacidad de explicar ideas t√©cnicas a perfiles diversos
* Propuestas de mejora y evaluaci√≥n de procesos
* Gesti√≥n de equipos multidisciplinares
* Resoluci√≥n de incidencias con an√°lisis y calma
* Priorizaci√≥n y gesti√≥n simult√°nea de m√∫ltiples proyectos
* **Aprendizaje continuo:** Podcast, libros, certificaciones, etc.

---

¬øTe gustar√≠a que lo formatee como un archivo `.md` descargable o subirlo a alguna plataforma?

"""

# Cliente Azure OpenAI
@st.cache_resource
def get_openai_client():
    return AsyncAzureOpenAI(
        azure_deployment=os.getenv("AZURE_DEPLOYMENT_NAME"),
        azure_endpoint=os.getenv("AZURE_ENDPOINT"),
        api_key=os.getenv("AZURE_API_KEY"),
        api_version="2024-12-01-preview"
    )

## --- MODELOS PYDANTIC ---##
class WeatherResponse(BaseModel):
    Ciudad: str
    Temperatura: float

class BookAuthor(BaseModel):
    Autor: str
    Titulo: str

class ContentModeration(BaseModel):
    is_appropiate: bool
    reasoning: str
    risk_level: Literal['low', 'medium', 'high']

## --- FUNCIONES HERRAMIENTAS ---##
def get_image_as_base64(path):
    with open(path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

image_base64 = get_image_as_base64("1700566366811.jpg")
image_html = f'<img src="data:image/png;base64,{image_base64}" width="24" style="vertical-align:middle; margin-right:8px;">'
@function_tool
def get_weather(latitude, longitude) -> str:
    try:
        response = requests.get(f"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m",verify=False)
        data = response.json()
        return data['current']['temperature_2m']
    except Exception as e:
        error_msg= f"Error retrieving weather data: {e}"
        return error_msg

@function_tool
def get_book_author(book_title: str) -> str:
    """Obtiene el autor de un libro dado su t√≠tulo"""
    try:
        response = requests.get(f"https://openlibrary.org/search.json?q={book_title}", timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if data.get('docs') and len(data['docs']) > 0:
            return str(data['docs'][0].get('author_name', ['Autor desconocido'])[0])
        return "Autor no encontrado"
    except Exception as e:
        return f"Error buscando el autor: {str(e)}"

def assemble_conversation(result,query):
    if result != None:
        query = result.to_input_list() + [{'role':"user",'content':query}]
    else:
        query = [{'role':"user",'content':query}]
    return query


## --- GUARDRAILS ---##
async def content_moderation_function(ctx, agent, query):
    """Funci√≥n de moderaci√≥n de contenido"""
    try:
        content_to_moderate = ""
        if isinstance(query, list):
            for item in query:
                if isinstance(item, dict) and item.get('role') == 'user':
                    content_to_moderate = item.get('content', '')
                    break
        elif isinstance(query, str):
            content_to_moderate = query
        else:
            content_to_moderate = str(query)
        
        result = await Runner.run(st.session_state.content_moderation_agent, content_to_moderate, context=ctx.context)
        final_output = result.final_output_as(ContentModeration)
        
        return GuardrailFunctionOutput(
            output_info=final_output,
            tripwire_triggered=not final_output.is_appropiate,
        )
    except Exception as e:
        return GuardrailFunctionOutput(
            output_info=ContentModeration(
                is_appropiate=True,
                reasoning=f"Error en moderaci√≥n: {str(e)}",
                risk_level="low"
            ),
            tripwire_triggered=False,
        )

## --- INICIALIZACI√ìN DE AGENTES ---##
@st.cache_resource
def initialize_agents():
    """Inicializa todos los agentes"""
    client = get_openai_client()
    set_tracing_disabled(disabled=True)
    
    # Agente meteorol√≥gico
    Weather_Agent= Agent(
        name="Agente Meteorologico",
        instructions="Eres un agente encargado de devolver la temperatura de la ciudad solicitada",
        model=OpenAIChatCompletionsModel(
            model="GPT-4o-structured",
            openai_client=client),
        tools=[get_weather],
        output_type=WeatherResponse
    )

    # Agente bibliotecario
    library_agent = Agent(
        name="Agente Bibliotecario",
        instructions="Respondes con el autor del libro solicitado.",
        model=OpenAIChatCompletionsModel(model="GPT-4o-structured", openai_client=client),
        tools=[get_book_author],
        output_type=BookAuthor
    )
    
    # Agente de √Ålvaro
    alvaro_agent = Agent(
        name="Agente de √Ålvaro",
        instructions=f"Eres un agente que responde preguntas sobre √Ålvaro bas√°ndote en la informaci√≥n que tienes de √©l.\n\nInformaci√≥n:{CONTEXT}",
        model=OpenAIChatCompletionsModel(model="GPT-4o-structured", openai_client=client),
    )
    
    # Agente de moderaci√≥n
    content_moderation_agent = Agent(
        name="Content Moderation Agent",
        instructions="""Eres un agente encargado de moderar el contenido de las conversaciones.
        Eval√∫a si el contenido es apropiado y clasifica el riesgo como low, medium o high.
        Si el contenido es inapropiado, establece is_appropiate=False.""",
        model=OpenAIChatCompletionsModel(model="GPT-4o-structured", openai_client=client),
        output_type=ContentModeration,
    )
    
    # Agente principal
    main_agent = Agent(
        name="√Ålvaro Agent",
        instructions=(
            "Eres un agente que utiliza las diferentes funciones para obtener la informaci√≥n solicitada. "
            "Utiliza las herramientas apropiadas seg√∫n el tipo de consulta."
        ),
        model=OpenAIChatCompletionsModel(model="GPT-4o-structured", openai_client=client),
        tools=[
            Weather_Agent.as_tool(
                tool_name="Agente_Meteorologico",
                tool_description="Agente para consultas meteorol√≥gicas"
            ),
            alvaro_agent.as_tool(
                tool_name="Agente_de_Alvaro",
                tool_description="Agente para preguntas sobre √Ålvaro"
            ),
            library_agent.as_tool(
                tool_name="Agente_Bibliotecario",
                tool_description="Agente para consultas sobre libros"
            ),
        ],
        input_guardrails=[InputGuardrail(guardrail_function=content_moderation_function)]
    )
    
    return {
        "main_agent": main_agent,
        "content_moderation_agent": content_moderation_agent,
        "weather_agent": Weather_Agent,
        "library_agent": library_agent,
        "alvaro_agent": alvaro_agent
    }

## --- FUNCIONES DE LA INTERFAZ ---##
def initialize_session_state():
    """Inicializa el estado de la sesi√≥n"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "conversation_result" not in st.session_state:
        st.session_state.conversation_result = None
    
    if "interaction_count" not in st.session_state:
        st.session_state.interaction_count = 0
    
    if "agents_initialized" not in st.session_state:
        agents = initialize_agents()
        for key, agent in agents.items():
            setattr(st.session_state, key, agent)
        st.session_state.agents_initialized = True

def display_message(role, content, timestamp=None, message_type="normal"):
    """Muestra un mensaje en el chat"""
    if timestamp is None:
        timestamp = datetime.now().strftime("%H:%M:%S")
    
    if role == "user":
        icon = "üë§"
        css_class = "user-message"
    else:
        icon = image_html
        css_class = "assistant-message"
    
    if message_type == "error":
        css_class = "error-message"
        icon = "‚ùå"
    elif message_type == "warning":
        css_class = "warning-message"
        icon = "‚ö†Ô∏è"
    elif message_type == "success":
        css_class = "success-message"
        icon = "‚úÖ"
    
    st.markdown(f"""
    <div class="chat-message {css_class}">
        <strong>{icon} {role.title()}</strong> <small>({timestamp})</small><br>
        {content}
    </div>
    """, unsafe_allow_html=True)

async def process_message(user_input):
    """Procesa un mensaje del usuario"""
    try:
        # Ensamblar conversaci√≥n
        formatted_query = assemble_conversation(st.session_state.conversation_result, user_input)
        
        # Ejecutar agente principal
        result = await Runner.run(st.session_state.main_agent, formatted_query)
        
        # Actualizar estado
        st.session_state.conversation_result = result
        st.session_state.interaction_count += 1
        
        return result.final_output, None
        
    except InputGuardrailTripwireTriggered as e:
        st.session_state.interaction_count += 1
        return f"\nüõ°Ô∏è CONTENIDO BLOQUEADO POR SEGURIDAD {e.guardrail_result.output.output_info.reasoning}", None
    except Exception as e:
        return None, f"Error inesperado: {str(e)}"

## --- INTERFAZ PRINCIPAL ---##
def main():
    """Funci√≥n principal de la interfaz"""
    initialize_session_state()
    
    # Header principal
    st.markdown("""
    <div class="main-header">
        <h1>ü§ñ Chatbot √Ålvaro - OpenAI Agents SDK</h1>
        <p>Asistente inteligente con protecciones de seguridad integradas</p>
        <p>PROPIEDAD INTELECTUAL DE ALVARO GONZALEZ BIELZA</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar con informaci√≥n
    with st.sidebar:
        st.header("üìä Informaci√≥n del Sistema")
        
        # M√©tricas
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Interacciones", st.session_state.interaction_count)
        with col2:
            st.metric("Mensajes", len(st.session_state.messages))
        
        st.markdown("---")
        
        # Capacidades del bot
        st.header("üéØ Capacidades")
        st.markdown("""
        - **üìä Informaci√≥n sobre √Ålvaro Gonz√°lez Bielza**
        - **üå§Ô∏è Consultas meteorol√≥gicas**
        - **üìö Informaci√≥n sobre libros y autores**
        - **üõ°Ô∏è Moderaci√≥n de contenido autom√°tica**
        """)
        
        st.markdown("---")
        
        # Controles
        st.header("‚öôÔ∏è Controles")
        if st.button("üóëÔ∏è Limpiar Conversaci√≥n", type="secondary"):
            st.session_state.messages = []
            st.session_state.conversation_result = None
            st.session_state.interaction_count = 0
            st.rerun()
        
        # Informaci√≥n t√©cnica
        st.header("üîß Informaci√≥n T√©cnica")
        st.info(f"""
        **Modelo**: GPT-4o-structured  
        **Guardrails**: Activos  
        **Estado**: {'üü¢ Conectado' if st.session_state.agents_initialized else 'üî¥ Desconectado'}
        """)
    
    # √Årea principal de chat
    st.header("üí¨ Conversaci√≥n")
    
    # Contenedor de mensajes
    chat_container = st.container()
    
    with chat_container:
        # Mostrar mensajes existentes
        for message in st.session_state.messages:
            display_message(
                message["role"], 
                message["content"], 
                message.get("timestamp"),
                message.get("type", "normal")
            )
    
    # Input del usuario
    st.markdown("---")
    
    # Formulario para enviar mensajes
    with st.form(key="chat_form", clear_on_submit=True):
        col1, col2 = st.columns([4, 1])
        
        with col1:
            user_input = st.text_input(
                "Escribe tu mensaje:",
                placeholder="Preg√∫ntame sobre √Ålvaro, el clima o libros...",
                key="user_input"
            )
        
        with col2:
            submit_button = st.form_submit_button("Enviar üì§", type="primary")
    
    # Procesar mensaje
    if submit_button and user_input:
        # Agregar mensaje del usuario
        timestamp = datetime.now().strftime("%H:%M:%S")
        st.session_state.messages.append({
            "role": "user",
            "content": user_input,
            "timestamp": timestamp,
            "type": "normal"
        })
        
        # Mostrar indicador de procesamiento
        with st.spinner("üîç Procesando con guardrails de seguridad..."):
            # Procesar mensaje de forma as√≠ncrona
            response, error = asyncio.run(process_message(user_input))
        
        if error:
            # Mostrar error
            st.session_state.messages.append({
                "role": "sistema",
                "content": error,
                "timestamp": datetime.now().strftime("%H:%M:%S"),
                "type": "error"
            })
        else:
            # Mostrar respuesta
            st.session_state.messages.append({
                "role": "asistente",
                "content": response,
                "timestamp": datetime.now().strftime("%H:%M:%S"),
                "type": "normal"
            })
        
        # Recargar la p√°gina para mostrar los nuevos mensajes
        st.rerun()
    
    # Ejemplos de consultas
    if len(st.session_state.messages) == 0:
        st.header("üí° Ejemplos de consultas")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("¬øCu√°l es el color favorito de √Ålvaro?"):
                st.session_state.messages.append({
                    "role": "user",
                    "content": "¬øCu√°l es el color favorito de √Ålvaro?",
                    "timestamp": datetime.now().strftime("%H:%M:%S"),
                    "type": "normal"
                })

                # Mostrar indicador de procesamiento
                with st.spinner("üîç Procesando con guardrails de seguridad..."):
                # Procesar mensaje de forma as√≠ncrona
                    response, error = asyncio.run(process_message("¬øCu√°l es el color favorito de √Ålvaro?"))

                # Mostrar respuesta
                st.session_state.messages.append({
                "role": "asistente",
                "content": response,
                "timestamp": datetime.now().strftime("%H:%M:%S"),
                "type": "normal"
                })
                st.rerun()
        
        with col2:
            if st.button("¬øQu√© temperatura hace en Madrid?"):
                st.session_state.messages.append({
                    "role": "user",
                    "content": "¬øQu√© temperatura hace en Madrid? (latitud: 40.4168, longitud: -3.7038)",
                    "timestamp": datetime.now().strftime("%H:%M:%S"),
                    "type": "normal"
                })
                # Mostrar indicador de procesamiento
                with st.spinner("üîç Procesando con guardrails de seguridad..."):
                # Procesar mensaje de forma as√≠ncrona
                    response, error = asyncio.run(process_message("¬øQu√© temperatura hace en Madrid?"))

                # Mostrar respuesta
                st.session_state.messages.append({
                "role": "asistente",
                "content": response,
                "timestamp": datetime.now().strftime("%H:%M:%S"),
                "type": "normal"
                })
                st.rerun()
        
        with col3:
            if st.button("¬øQui√©n escribi√≥ El Quijote?"):
                st.session_state.messages.append({
                    "role": "user",
                    "content": "¬øQui√©n escribi√≥ Don Quijote de la Mancha?",
                    "timestamp": datetime.now().strftime("%H:%M:%S"),
                    "type": "normal"
                })
                # Mostrar indicador de procesamiento
                with st.spinner("üîç Procesando con guardrails de seguridad..."):
                # Procesar mensaje de forma as√≠ncrona
                    response, error = asyncio.run(process_message("¬øQui√©n escribi√≥ Don Quijote de la Mancha?"))

                # Mostrar respuesta
                st.session_state.messages.append({
                "role": "asistente",
                "content": response,
                "timestamp": datetime.now().strftime("%H:%M:%S"),
                "type": "normal"
                })
                st.rerun()

if __name__ == "__main__":
    main()